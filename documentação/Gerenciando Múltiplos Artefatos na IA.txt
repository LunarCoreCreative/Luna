Arquitetura de Sistemas Multi-Artefato em Agentes de LLM: Estratégias de Gerenciamento de Estado, Orquestração e Persistência para a Plataforma Luna
1. Introdução à Mudança de Paradigma: De Chat Efêmero para Telas Persistentes
A evolução dos Grandes Modelos de Linguagem (LLMs) está a transitar de uma interação baseada puramente em diálogo sequencial para ambientes de colaboração baseados em artefatos, frequentemente referidos como interfaces "Canvas" ou arquiteturas baseadas em projetos. A solicitação referente à arquitetura "Luna" reflete um desafio crítico e ubíquo na engenharia de software de IA moderna: a instabilidade sistêmica quando se tenta transcender a janela de contexto linear para gerenciar múltiplos objetos de estado mutável. O erro relatado — instabilidade ao criar um segundo artefato ou ao alternar entre tipos de conteúdo (código versus prosa) — não é meramente um bug de implementação, mas um sintoma de uma falha fundamental na gestão de estado e na orquestração de contexto.1
Sistemas tradicionais tratam o histórico de conversação como um fluxo único e imutável de tokens. Quando um usuário solicita a criação de um código e, subsequentemente, um artigo explicativo, uma arquitetura linear tenta comprimir a representação de ambos no mesmo vetor de atenção. Isso resulta em "colisões de contexto", onde as instruções de sistema para codificação contaminam a geração de texto, ou onde a modificação de um artefato é alucinada como uma modificação em outro. Para suportar múltiplos artefatos robustos e referências cruzadas dinâmicas, a arquitetura da Luna deve evoluir de uma máquina de estados finitos simples para um Sistema Multi-Agente Baseado em Grafos (Graph-Based Multi-Agent System), sustentado por protocolos rigorosos de definição de contexto e esquemas de dados tipados.3
Este relatório detalha uma estratégia exaustiva para reestruturar a gestão de estado da Luna, integrando padrões de design do Model Context Protocol (MCP), orquestração via LangGraph, e técnicas avançadas de engenharia de contexto para edição de arquivos. A análise aborda desde a teoria da fragmentação de estado até a implementação prática de ferramentas de edição atômica, visando uma solução de nível industrial para a estabilidade e escalabilidade da plataforma.
________________
2. Diagnóstico de Falhas em Arquiteturas Monolíticas de Artefatos
2.1 A Falácia do Fluxo Único e a Fragmentação de Estado
A instabilidade observada na Luna ao tentar alternar entre a criação de código e a escrita de um artigo deriva da tentativa de gerenciar estados complexos e paralelos dentro de uma estrutura de dados sequencial. Em modelos padrão, o "estado" é implicitamente definido pela sequência de mensagens ``. Quando um artefato é gerado, ele existe apenas como uma substring dentro de uma mensagem Assistant.
Ao solicitar um segundo artefato, o sistema enfrenta o que a literatura classifica como falha de coordenação e especificação.5 Sem um registro explícito fora da janela de contexto, o modelo não possui uma representação "mental" de que existem dois objetos distintos (o código e o artigo). Ele "vê" apenas texto anterior. Isso leva a três modos de falha primários:
1. Poluição de Prompt (Prompt Leaking): Se o System Prompt inicial foi configurado para "Você é um especialista em Python", essa instrução persiste mesmo quando a tarefa muda para "Escrever um prólogo". O modelo, tentando obedecer à instrução primária, pode inserir blocos de código desnecessários no texto ou adotar um tom excessivamente técnico, resultando no comportamento "bugado" descrito.7
2. Perda de Referência (Context Rot): À medida que a conversa avança, os tokens iniciais (contendo o primeiro artefato) são comprimidos ou truncados. Se o segundo artefato precisa referenciar o primeiro, o modelo pode alucinar detalhes do código original porque a representação exata já não está disponível ou está diluída no meio do contexto ("Lost in the Middle phenomenon").9
3. Ambiguidade de Mutação: Se o usuário diz "altere o segundo parágrafo", e ambos os artefatos estão no histórico, o modelo não tem um ponteiro determinístico para saber qual artefato é o alvo da edição.
2.2 Taxonomia de Falhas em Sistemas Multi-Agente
A pesquisa recente sobre falhas em sistemas multi-agente (MAS) identifica que quase 42% dos erros em produção derivam de problemas de especificação e 37% de falhas de coordenação.11 No caso da Luna, a falha ao alternar contextos é uma falha de coordenação. O sistema carece de um "Supervisor" que entenda que a intenção do usuário mudou de um domínio (Codificação) para outro (Escrita Criativa) e que, consequentemente, o estado ativo e as ferramentas disponíveis devem ser trocados.
A tabela abaixo resume a classificação das falhas prováveis na arquitetura atual da Luna e as soluções arquiteturais correspondentes propostas neste relatório:
Modo de Falha
	Sintoma na Luna
	Causa Raiz Arquitetural
	Solução Proposta
	Desvio de Especificação
	Modelo gera código quando deveria escrever texto (ou vice-versa).
	Prompt de sistema estático e persistente.
	Orquestração Dinâmica: Supervisor que altera o System Prompt com base no artefato ativo.
	Perda de Contexto
	Referências cruzadas incorretas ou alucinações sobre o primeiro artefato.
	Dependência exclusiva da janela de contexto linear.
	Estado Gerenciado (State Graph): Registro persistente de artefatos fora do histórico de chat.
	Erro de Edição
	"Bug" ao tentar aplicar alterações ou criar novos arquivos.
	Ferramentas de edição imprecisas (ex: reescrita total).
	Edição Baseada em Blocos: Ferramentas de Search/Replace determinísticas (Padrão Aider).
	Colisão de Estado
	O sistema trava ou confunde conteúdos de artefatos.
	Variável global única para "conteúdo atual".
	Registro de Artefatos: Dicionário estruturado suportando N artefatos simultâneos.
	________________
3. Fundamentos da Arquitetura de Estado Orientada a Grafos (Graph-Based State)
Para resolver a instabilidade da Luna, é imperativo migrar de uma gestão de estado baseada em listas (chat history) para uma gestão baseada em grafos, utilizando princípios encontrados em frameworks como LangGraph.3 Em um grafo de estado, a conversa é apenas um dos nós; os artefatos, as referências e os metadados são entidades de primeira classe que persistem e evoluem independentemente do fluxo de mensagens.
3.1 Definição do Esquema de Estado Global (State Schema)
O coração da nova arquitetura da Luna deve ser um esquema de dados rigorosamente tipado. Utilizando estruturas como TypedDict ou modelos Pydantic, definimos exatamente o que constitui o "Estado" do sistema em qualquer milissegundo. O estado não é apenas memória; é a verdade absoluta da aplicação.
Diferente de sistemas simples que apenas anexam mensagens (operator.add), um sistema multi-artefato requer Redutores de Estado complexos que saibam como atualizar, substituir ou arquivar artefatos específicos sem perder o histórico.13
3.1.1 Estrutura Recomendada do Esquema Luna
O esquema deve ser dividido em canais de comunicação (mensagens) e canais de dados (artefatos).


Python




# Representação Conceitual do Esquema de Estado da Luna

class ArtifactMetadata(TypedDict):
   id: str                  # UUID único
   type: str                # ex: 'code/python', 'text/markdown', 'image/svg'
   title: str               # Nome do arquivo ou título
   version: int             # Contador de revisão para controle de concorrência
   dependencies: List[str]  # IDs de outros artefatos referenciados
   status: str              # 'active', 'archived', 'generating'

class ArtifactContent(TypedDict):
   content: str             # O corpo atual do artefato
   summary: str             # Resumo comprimido para inclusão em contextos limitados

class LunaState(TypedDict):
   # Canal de Mensagens: Histórico linear da conversa (Append-Only)
   messages: Annotated, operator.add]
   
   # Registro de Artefatos: Dicionário mutável de todos os artefatos criados
   # A chave é o UUID do artefato. O redutor aqui deve mesclar atualizações.
   artifacts: Annotated, merge_artifacts]
   
   # Metadados: Índice leve para o Supervisor consultar sem carregar conteúdos
   artifact_index: Annotated, update_index]
   
   # Ponteiro de Foco: Qual artefato está visível/editável no momento
   active_artifact_id: Optional[str]
   
   # Modo de Agente: O 'chapéu' que a Luna está usando (Coder, Writer, Reviewer)
   current_mode: Literal["architect", "coder", "writer", "reviewer"]

3.2 O Papel dos Redutores (Reducers) na Mutação de Artefatos
Em arquiteturas como LangGraph, quando um nó (agente) termina sua execução, ele retorna uma atualização de estado. Para mensagens, a atualização é simplesmente "adicionar esta nova mensagem". Para artefatos, a lógica é mais sutil.
Se a Luna cria um segundo artefato, o redutor não deve sobrescrever o dicionário de artefatos. Ele deve receber um patch do dicionário e mesclá-lo.
* Criação: O agente retorna {"artifacts": {"novo_id": "conteúdo"}}. O redutor adiciona essa chave.
* Edição: O agente retorna {"artifacts": {"id_existente": "novo_conteúdo"}}. O redutor substitui o valor para aquela chave específica, mantendo os outros artefatos intactos.12
Isso resolve o bug relatado: ao usar um dicionário gerenciado por redutores, a criação do "artigo explicativo" (segundo artefato) não compete pelo mesmo espaço de memória do "código" (primeiro artefato). Ambos coexistem no estado global, e a variável active_artifact_id determina apenas qual deles é renderizado na interface ou priorizado no contexto do LLM.
3.3 Persistência e "Time-Travel"
Para suportar sessões longas e complexas, o estado deve ser persistido em um banco de dados (SQLite, Postgres) através de um mecanismo de Checkpointing. Isso permite que a Luna suporte "viagem no tempo": se uma edição no segundo artefato corromper a referência ao primeiro, o usuário pode reverter o estado global para um checkpoint anterior, recuperando a integridade de todos os artefatos simultaneamente.3
________________
4. Orquestração Multi-Agente: O Padrão Supervisor
Para gerenciar a alternância entre tipos de artefatos (ex: código vs. texto), a arquitetura monolítica (um único prompt para tudo) deve ser abandonada em favor de uma arquitetura hierárquica de agentes. O padrão Supervisor é o mais adequado para a Luna, pois centraliza a decisão de roteamento e mantém o controle sobre o estado global.17
4.1 O Agente Supervisor (Router)
O Supervisor é um nó no grafo que não gera conteúdo. Sua única função é analisar a intenção do usuário e o estado atual para decidir qual "trabalhador" (Worker) deve ser ativado.
Lógica de Decisão do Supervisor:
1. Entrada: Última mensagem do usuário + Metadados dos artefatos (sem conteúdo).
2. Análise: O usuário quer criar algo novo? Editar algo existente? Ou apenas conversar?
3. Roteamento:
   * Se o pedido é "crie um script Python", roteia para o CoderAgent e define current_mode="coder".
   * Se o pedido é "escreva um artigo sobre esse script", roteia para o WriterAgent, define current_mode="writer", e marca o script existente como uma dependência de leitura.
Este roteamento explícito resolve o bug de "contexto misturado". Quando o controle passa para o WriterAgent, este agente é inicializado com um System Prompt específico para escrita (ex: "Você é um autor técnico..."), completamente isolado das instruções de codificação anteriores. O estado global garante que os dados persistem, mas o "comportamento" do modelo é trocado dinamicamente.20
4.2 Agentes Especializados (Workers)
Cada tipo de artefato deve ser gerenciado por um sub-agente especializado com ferramentas próprias.
* CoderAgent:
   * Ferramentas: write_code, run_tests, linter, search_stack_overflow.
   * Prompt: Focado em sintaxe, eficiência, PEP8, e uso de ferramentas de diff para edição.
   * Comportamento: Recebe o artefato de código como mutável.
* WriterAgent:
   * Ferramentas: write_markdown, research_topic, read_artifact.
   * Prompt: Focado em clareza, tom, estrutura narrativa e formatação Markdown.
   * Comportamento: Recebe artefatos de código como somente leitura para referência.22
A separação garante que, ao pedir para "alterar essa informação no parágrafo tal", o Supervisor ative o WriterAgent, que entende semanticamente o que é um "parágrafo", diferentemente do CoderAgent que opera em linhas de código ou funções.
4.3 Implementação de Handoffs (Transferências)
A arquitetura deve suportar transferências suaves. Se o CoderAgent percebe que precisa de uma explicação textual complexa nos comentários, ele pode sinalizar ao Supervisor para transferir a tarefa temporariamente para o WriterAgent, e depois receber o controle de volta. Isso é implementado via ferramentas de handoff (ex: transfer_to_writer), que retornam uma instrução de controle ao grafo em vez de uma resposta final.19
________________
5. Protocolo de Contexto do Modelo (MCP) e Integração
Para garantir que a Luna seja extensível e compatível com ferramentas externas (como IDEs locais ou bancos de dados), a implementação deve seguir o Model Context Protocol (MCP). O MCP padroniza como os artefatos são expostos aos LLMs, funcionando como uma camada de abstração entre o armazenamento de dados e a inteligência.24
5.1 Artefatos como Recursos MCP (Resources)
Na terminologia MCP, cada artefato na Luna deve ser exposto como um Recurso.
* URI Scheme: luna://artifacts/{artifact_id} ou luna://artifacts/{artifact_id}/version/{v}.
* Interface: O servidor MCP da Luna implementa os endpoints resources/list e resources/read.
Quando o Supervisor decide que o Agente precisa "ler" um artefato anterior para criar um novo, ele não copia e cola o texto no prompt. Em vez disso, ele instrui o ambiente a carregar o recurso via MCP. Isso permite:
1. Carregamento Sob Demanda (Lazy Loading): O conteúdo do artefato só entra na janela de contexto se explicitamente solicitado, economizando tokens e reduzindo a confusão do modelo.26
2. Abstração de Fonte: No futuro, um artefato pode não estar na memória da Luna, mas sim em um repositório GitHub ou Google Drive conectado via MCP. A arquitetura trata ambos da mesma forma.
5.2 Ferramentas como Capacidades MCP (Tools)
As ações de manipulação de artefatos devem ser expostas como Ferramentas MCP:
* create_artifact(name, type, content)
* update_artifact(id, patch)
* link_artifacts(source_id, target_id, relation_type)
Ao definir essas operações via esquema JSON padronizado do MCP, a Luna garante que qualquer modelo (Claude, GPT-4, modelos locais via Ollama) possa interagir com o sistema sem necessidade de reengenharia de prompt específica para cada modelo.28
________________
6. Mecanismos de Edição e Mutação: Resolvendo o Problema da Atualização
Um ponto crítico mencionado na solicitação é a falha ao tentar editar ("Altere essa informação no parágrafo tal"). Modelos de linguagem frequentemente lutam com edições precisas quando solicitados a reescrever arquivos inteiros (devido à "preguiça" do modelo ou truncamento) ou quando usam números de linha (que são instáveis).
6.1 Estratégias de Edição: Comparativo
A pesquisa sobre ferramentas como Aider e Canvas sugere que a escolha do formato de edição é determinante para a estabilidade.30
Formato de Edição
	Descrição
	Prós
	Contras
	Recomendação Luna
	Full Rewrite (Whole)
	O modelo reescreve o artefato inteiro com as mudanças.
	Simples de implementar; baixa chance de erro de sintaxe.
	Custo alto de tokens; lento; propenso a truncamento em arquivos grandes.
	Apenas para artefatos pequenos (<50 linhas).
	Line Numbers
	"Substitua linhas 10-15 por X".
	Economia de tokens.
	Altíssima taxa de erro; LLMs são péssimos contadores de linhas.
	Não usar.
	Unified Diff
	Formato padrão diff do Git.
	Padrão industrial; compacto.
	LLMs frequentemente erram o cabeçalho ou contexto do diff.
	Usar apenas com modelos muito avançados (GPT-4o).
	Search/Replace Block
	O modelo fornece um bloco de texto original (para buscar) e o novo (para substituir).
	Alta precisão; robusto a mudanças de linha; intuitivo para o modelo.
	Requer unicidade no bloco de busca.
	Altamente Recomendado.
	6.2 Implementação do Bloco Search/Replace (Padrão Aider)
Para a Luna, recomenda-se adotar o formato de bloco de busca e substituição, amplamente validado pela ferramenta Aider como o mais robusto para edição multi-arquivo.33
Schema da Ferramenta edit_artifact:


JSON




{
 "name": "edit_artifact",
 "description": "Edits a text or code artifact by replacing a specific block of text.",
 "parameters": {
   "type": "object",
   "properties": {
     "artifact_id": {"type": "string"},
     "search_block": {
       "type": "string", 
       "description": "The EXACT text chunk to be replaced. Must match the existing content character-for-character, including whitespace."
     },
     "replace_block": {
       "type": "string", 
       "description": "The new text chunk to insert in place of the search_block."
     }
   },
   "required": ["artifact_id", "search_block", "replace_block"]
 }
}

Quando o agente Writer envia essa solicitação, o backend da Luna executa uma correspondência de string (fuzzy ou exata) para localizar o search_block no artefato alvo e aplicar a substituição. Se o bloco não for encontrado (ex: o modelo alucinou o texto original), o sistema retorna um erro claro: "Search block not found. Please quote the original text exactly.". Isso força o modelo a se corrigir na próxima iteração, criando um loop de autocura robusto.32
________________
7. Referências Cruzadas e Gerenciamento de Dependências
Para suportar a exigência de referências cruzadas ("artigo sobre o código"), a Luna deve manter um grafo de dependências explícito.
7.1 O Grafo de Dependência Semântica
Além do dicionário de artefatos, o estado deve conter uma lista de arestas artifact_relations.
* Quando o WriterAgent é ativado para explicar o CoderArtifact, o sistema cria uma aresta: WriterArtifact -> (depends_on) -> CoderArtifact.
7.2 Validação de Integridade (Stale Check)
Esta estrutura permite funcionalidades avançadas de consistência. Se o usuário pedir para o CoderAgent alterar a função principal no CoderArtifact, o sistema detecta (via grafo) que o WriterArtifact depende dele.
* Ação Automática: O sistema marca o WriterArtifact com um status de "Desatualizado" (Stale).
* Prompt de Sistema: Na próxima vez que o usuário interagir com o artigo, o Supervisor recebe um aviso: "Atenção: O código base deste artigo foi modificado. Sugira ao usuário uma atualização do texto."
* Prevenção de Alucinação: Isso impede que o artigo descreva uma versão do código que já não existe, mantendo a coerência narrativa do projeto como um todo.7
________________
8. Estratégias de Engenharia de Contexto para Múltiplos Artefatos
Com múltiplos artefatos, o desafio final é o gerenciamento da janela de contexto. Enviar todos os artefatos para o LLM a cada turno é inviável e caro.
8.1 Compilação de Contexto Dinâmica
O sistema deve implementar uma etapa de "Compilação de Contexto" antes de chamar o LLM.35
1. Identificação do Foco: Qual é o active_artifact_id? Esse artefato é carregado na íntegra.
2. Resolução de Dependências: Quais artefatos estão ligados ao ativo via artifact_relations? Estes são carregados, possivelmente em modo resumido ou somente-leitura.
3. Metadados: Uma lista de todos os outros artefatos (apenas Título e Tipo) é incluída para que o modelo saiba o que existe no projeto e possa solicitar acesso via ferramentas.
8.2 Representação XML/Markdown Estruturada
Para evitar que o modelo confunda o artefato com as instruções, o conteúdo deve ser encapsulado em tags XML claras dentro do prompt, uma técnica validada pela Anthropic para o Claude.36
Exemplo de Prompt Montado:


XML




<system>
Você é um assistente de escrita. O usuário está editando o artigo ID: art_002.
</system>

<context>
 <artifact id="art_001" type="code/python" mode="read_only">
   def hello_world(): print("Hello")
 </artifact>
 
 <artifact id="art_002" type="text/markdown" mode="active_write">
   # Introdução
   Este artigo explica o script...
 </artifact>
</context>

<instructions>
Use a ferramenta 'edit_artifact' para modificar o art_002. Não tente modificar art_001.
</instructions>

Essa estrutura rígida ajuda o modelo a entender as fronteiras de cada objeto, eliminando o "bug" de mistura de tipos ou edição do arquivo errado.
________________
9. Conclusão e Roteiro de Implementação
A instabilidade da plataforma Luna ao lidar com múltiplos artefatos não é um defeito de um componente isolado, mas uma limitação sistêmica da gestão de estado linear. A solução exige uma rearquitetura para um modelo orientado a grafos, onde o estado é persistente, estruturado e gerenciado por agentes especializados sob supervisão.
Para implementar essas mudanças, recomenda-se o seguinte roteiro técnico:
1. Fase 1: Endurecimento do Estado (State Hardening): Migrar de variáveis simples para um esquema TypedDict robusto (usando LangGraph) que suporte um registro (dicionário) de artefatos com controle de versão. Implementar redutores para operações de merge de estado.
2. Fase 2: Orquestração Supervisor-Worker: Implementar o nó Supervisor e separar os prompts de sistema para Agentes de Código e Agentes de Escrita. Garantir que a troca de contexto limpe as instruções anteriores.
3. Fase 3: Ferramentas de Edição Robusta: Substituir qualquer lógica de reescrita total ou baseada em linhas pela implementação de ferramentas de apply_patch usando blocos de Search/Replace determinísticos.
4. Fase 4: Protocolo MCP e Grafos de Dependência: Padronizar os artefatos como recursos MCP e implementar o rastreamento de referências cruzadas para alertas de consistência.
Ao adotar esta arquitetura, a Luna evoluirá de um chatbot linear para um verdadeiro ambiente de desenvolvimento cognitivo, capaz de sustentar projetos complexos, interconectados e de longa duração com a estabilidade exigida por profissionais.
________________
Parte 1: Fundamentos Teóricos e Diagnóstico de Falhas em Sistemas Multi-Artefato
1.1 O Colapso da Arquitetura de Chat Linear
A arquitetura predominante em assistentes de IA, até recentemente, baseava-se no paradigma de "Chat Linear". Neste modelo, a interação entre humano e máquina é representada como uma lista sequencial de mensagens. O "estado" do sistema é, efetivamente, a soma dessa lista. Para tarefas simples de pergunta e resposta (Q&A), isso é suficiente. No entanto, quando introduzimos o conceito de "Artefatos" — objetos persistentes, estruturados e evolutivos, como arquivos de código, documentos de design ou relatórios — a arquitetura linear entra em colapso.
O problema central reside na sobrecarga semântica da janela de contexto. Em um chat linear, um artefato gerado (por exemplo, um bloco de código Python) é apenas um conjunto de tokens dentro de uma mensagem passada. Quando o usuário solicita "crie um segundo artefato" (um artigo explicativo), o primeiro artefato começa a ser "empurrado" para trás na janela de contexto deslizante.
Isso desencadeia dois fenômenos destrutivos para a estabilidade do sistema Luna:
1. Compressão de Atenção (Attention Sink/Loss): À medida que a conversa prossegue sobre o segundo artefato, a atenção do mecanismo de Self-Attention do Transformer sobre o primeiro artefato diminui. Detalhes críticos do código original (nomes de variáveis, lógica de borda) tornam-se "nebulosos" para o modelo, levando a alucinações nas referências cruzadas.9
2. Ambiguidade de Escopo: Se o histórico contém dois blocos de texto distintos (o código e o artigo), e o usuário envia um comando de edição vago ("mude o título"), o modelo linear não tem uma estrutura de dados explícita para saber qual dos dois blocos deve ser alterado. Ele tenta inferir pelo contexto recente, o que é propenso a erros, resultando na modificação do arquivo errado ou na tentativa de mesclar ambos.10
1.2 Análise do Bug da Luna: Colisão de Contexto e Falha de Modos
O relato de que a Luna "buga" ao alternar entre tipos diferentes (ex: código para artigo) aponta especificamente para uma falha na gestão de Modos de Operação. LLMs são altamente sensíveis ao System Prompt (instruções iniciais).
* Para gerar bom código, o prompt deve enfatizar lógica, sintaxe estrita e concisão.
* Para gerar boa prosa, o prompt deve enfatizar fluidez, criatividade e estrutura narrativa.
Em uma arquitetura monolítica, o System Prompt é muitas vezes estático ou definido apenas no início da sessão. Quando o usuário muda a tarefa de codificação para escrita, se o sistema não substituir dinamicamente o System Prompt e as ferramentas disponíveis, o modelo entra em um estado de conflito. Ele pode tentar escrever o artigo usando formatação de comentários de código (# Introdução vs // Introdução), ou tentar "executar" o texto como se fosse um script.7
Além disso, a criação do segundo artefato muitas vezes falha porque o sistema de gerenciamento de estado da Luna provavelmente utiliza uma variável singleton (ex: current_file). Ao iniciar o segundo arquivo, o primeiro é sobrescrito na memória de trabalho imediata. Sem um mecanismo de persistência secundária (um "registro" ou "banco de dados" de artefatos na sessão), o primeiro artefato deixa de existir para o sistema, embora ainda apareça visualmente no chat para o usuário. Essa dissonância entre o que o usuário vê (dois arquivos) e o que o sistema sabe (apenas o último arquivo) cria erros catastróficos de referência.6
1.3 Taxonomia de Falhas em Sistemas Multi-Agente (MAS)
Para desenhar uma solução robusta, devemos classificar os erros da Luna dentro da taxonomia formal de falhas de Sistemas Multi-Agente (MAS), conforme estabelecido em pesquisas recentes.5
1.3.1 Falhas de Coordenação (Coordination Failures)
Representam cerca de 37% das falhas em MAS. No contexto da Luna, isso ocorre quando o sistema não consegue sincronizar o estado entre a intenção do usuário e a execução do agente.
* Exemplo: O usuário pede para "explicar o código". O sistema deveria coordenar uma leitura do artefato de código e uma escrita no artefato de texto. Se a coordenação falha, o agente tenta escrever a explicação dentro do arquivo de código, corrompendo-o.
1.3.2 Falhas de Especificação (Specification Failures)
Representam cerca de 42% das falhas. Ocorrem quando o agente perde a noção de seu papel ou restrições.
* Exemplo: O agente "Writer" (Escritor) começa a alucinar correções de código no meio do artigo, violando a especificação de que ele deve apenas referenciar o código, não alterá-lo. Isso acontece frequentemente quando o contexto do "Writer" está poluído com muitos exemplos de codificação do turno anterior.
1.3.3 Falhas de Verificação (Verification Failures)
Falta de mecanismos para validar se a ação (criar segundo artefato) foi bem-sucedida antes de prosseguir.
* Exemplo: O modelo gera o texto do artigo, mas a ferramenta de sistema falha em salvar o arquivo. O modelo prossegue assumindo que o arquivo existe, levando a erros em cascata nas interações subsequentes.
A tabela a seguir resume como essas falhas teóricas se manifestam no problema prático da Luna:
Categoria de Falha (MAS)
	Manifestação na Luna
	Causa Técnica Provável
	Requisito de Correção
	Coordenação
	Bug ao alternar tipos (Code -> Text).
	Falta de transição explícita de System Prompt e ferramentas.
	Implementar padrão Supervisor/Router.
	Estado (Memória)
	Bug ao criar 2º artefato.
	Uso de variável única (current_doc) em vez de coleção.
	Implementar Registro de Artefatos (Dict/Map).
	Especificação
	Mistura de formatação ou estilo.
	Contexto poluído com instruções do modo anterior.
	Implementar Limpeza de Contexto na transição.
	Verificação
	Referências a código inexistente/antigo.
	Falta de checagem de integridade de links.
	Implementar Grafo de Dependência com validação.
	________________
Parte 2: Arquitetura de Estado Orientada a Grafos (LangGraph)
A solução para a estabilidade da Luna exige a adoção de uma Arquitetura de Estado Orientada a Grafos. Diferente da lista linear, um grafo permite modelar o fluxo da aplicação como uma série de nós (unidades de processamento) conectados por arestas (transições de controle), onde um objeto de Estado Global é passado e mutado de forma controlada.3 Frameworks como LangGraph são ideais para esta implementação.
2.1 Design do Esquema de Estado Global (State Schema)
O primeiro passo é definir formalmente o esquema de dados que a Luna irá manipular. Utilizando Python e a biblioteca typing, definimos uma estrutura TypedDict que garante que todos os agentes concordem sobre a forma dos dados.
2.1.1 O Objeto Artefato
Cada artefato não pode ser apenas uma string. Ele deve ser um objeto rico com metadados.


Python




class Artifact(TypedDict):
   id: str                  # Identificador único (UUID)
   type: str                # ex: 'application/python', 'text/markdown'
   title: str               # Nome de exibição
   content: str             # O corpo do artefato
   version: int             # Versão incremental (para controle de concorrência)
   created_at: str          # Timestamp ISO 8601
   last_modified: str       # Timestamp da última edição
   references: List[str]    # IDs de outros artefatos que este referencia
   status: Literal['active', 'archived', 'draft']

2.1.2 O Estado Global (OverallState)
O estado global da Luna deve conter o registro de todos os artefatos, além do histórico de conversação.


Python




from langgraph.graph import add_messages
from typing import Annotated

class LunaState(TypedDict):
   # Histórico de Conversa: Usa um redutor 'add_messages' para append-only
   messages: Annotated[List[AnyMessage], add_messages]
   
   # Registro de Artefatos: Usa um redutor customizado para merge/update
   artifacts: Annotated, update_artifacts_reducer]
   
   # Contexto de Foco
   active_artifact_id: Optional[str]  # Qual artefato está na tela principal
   visible_artifact_ids: List[str]    # Quais artefatos estão abertos em abas
   
   # Controle de Fluxo
   current_agent: str       # Quem está agindo? (Supervisor, Coder, Writer)
   next_action: str         # Intenção detectada pelo Supervisor

2.2 Lógica de Redutores (Reducers) para Mutação Segura
O conceito de Redutor é vital para evitar condições de corrida e inconsistências. Um redutor é uma função que pega o estado atual e uma atualização (delta) e retorna o novo estado.
Para a lista de mensagens, o redutor padrão add_messages é suficiente (apenas anexa). Para o dicionário de artefatos, precisamos de um redutor update_artifacts_reducer mais inteligente 12:
1. Imutabilidade Parcial: Se o agente retorna uma atualização apenas para o artefato ID A1, o redutor deve retornar um novo dicionário onde A1 é atualizado, mas A2, A3, etc., são preservados intactos.
2. Versionamento Automático: O redutor pode ser programado para incrementar automaticamente o campo version sempre que o conteúdo mudar.
3. Log de Auditoria: O redutor pode, opcionalmente, salvar o estado anterior em um histórico de undo/redo, permitindo que o usuário reverta alterações indesejadas (uma funcionalidade essencial em interfaces tipo Canvas).1
2.3 Persistência e Checkpointing (Time-Travel)
Para que a Luna suporte sessões longas onde o usuário alterna entre artefatos repetidamente, o estado deve ser persistido fora da memória RAM. LangGraph oferece suporte nativo a Checkpointers (usando SQLite, Postgres ou Redis).13
O Checkpointer salva um "snapshot" do LunaState a cada passo do grafo (cada "Super-step"). Isso habilita:
* Retomada de Sessão: O usuário pode fechar o navegador e voltar horas depois; o estado (incluindo artefatos não salvos e histórico de chat) é recarregado do banco de dados.
* Bifurcação (Branching): O usuário pode dizer "Volte para antes de eu pedir o artigo e vamos tentar criar um diagrama em vez disso". O sistema carrega o checkpoint anterior, efetivamente "viajando no tempo" e criando um novo ramo de execução.
* Depuração: Se ocorrer o bug de "alternância", os desenvolvedores podem inspecionar o checkpoint exato onde o estado corrompeu, vendo exatamente quais variáveis estavam definidas incorretamente.
2.4 Concorrência e Super-Steps
Em sistemas avançados, múltiplos agentes podem trabalhar simultaneamente (ex: um agente revisa o código enquanto outro escreve o artigo). O modelo de execução do LangGraph baseia-se em "Super-steps".
* Em um super-step, todos os nós ativos executam em paralelo.
* Suas atualizações de estado são coletadas.
* Ao final do passo, os redutores mesclam todas as atualizações.
* Se dois agentes tentarem editar o mesmo artefato no mesmo passo, o redutor deve detectar o conflito e rejeitar uma das atualizações ou tentar um merge inteligente. Para a Luna, recomenda-se inicialmente um bloqueio pessimista: apenas um agente pode ter permissão de escrita (active_write_access) sobre um artefato por vez.13
________________
Parte 3: Protocolos de Contexto e Padronização (MCP)
Para tornar a arquitetura da Luna interoperável e à prova de futuro, a implementação do suporte a artefatos deve seguir o Model Context Protocol (MCP). O MCP é um padrão aberto que define como aplicações de IA trocam contexto com fontes de dados e ferramentas.24
3.1 Artefatos como Recursos MCP (Resources)
No paradigma MCP, dados passivos (como arquivos, logs, ou neste caso, artefatos) são expostos como Recursos.
A Luna deve implementar um Servidor MCP interno que exponha seus artefatos sob um esquema de URI personalizado, por exemplo luna://workspace/{session_id}/artifacts/{artifact_id}.
Vantagens da Abordagem MCP:
1. Abstração: O Agente (Worker) não precisa saber se o artefato está na memória RAM, num banco SQLite ou num arquivo no disco. Ele apenas requisita o recurso via URI.
2. Subscrição de Mudanças: O MCP suporta um mecanismo de subscrição (subscribe). Se o WriterAgent está visualizando o código para escrever sobre ele, ele pode "assinar" o recurso de código. Se o CoderAgent alterar o código, o MCP notifica o WriterAgent, permitindo que ele saiba que sua referência está desatualizada (Stale Reference).25
3.2 Ferramentas como Capacidades MCP
As ações que a Luna pode realizar sobre os artefatos devem ser expostas como Ferramentas MCP.
Em vez de funções Python soltas, definimos esquemas JSON rigorosos para:
* artifacts/create: Cria novo recurso.
* artifacts/edit: Aplica patch a um recurso.
* artifacts/list: Lista recursos disponíveis na sessão.
Isso desacopla a lógica de negócio (como editar um arquivo) da lógica do modelo. Se no futuro a Luna mudar de GPT-4 para Claude 3.5 ou um modelo local Llama 3, as ferramentas MCP permanecem inalteradas, pois seguem um padrão agnóstico de modelo.26
________________
Parte 4: Mecanismos de Edição e Mutação de Artefatos
O ponto mais frágil relatado pelo usuário é o "bug" ao tentar criar ou alternar artefatos. Muitas vezes, isso é uma falha na camada de Edição. Como o modelo comunica a mudança?
4.1 O Problema da Reescrita Total vs. Patches
Em implementações ingênuas, quando o modelo quer alterar um parágrafo de um texto de 50 páginas, ele reescreve as 50 páginas com a alteração. Isso é:
* Lento: Latência inaceitável.
* Caro: Consumo massivo de tokens.
* Frágil: O modelo pode truncar o final do arquivo por atingir o limite de saída (max tokens), resultando em perda de dados catastrófica.
4.2 A Solução: Edição via Blocos de Busca/Substituição (Search/Replace Blocks)
A arquitetura da ferramenta Aider provou que o formato de edição mais robusto para LLMs não é o número de linha (que os modelos erram frequentemente) nem o formato diff unificado (que exige sintaxe complexa), mas sim o formato de Blocos de Busca e Substituição.30
Implementação Recomendada para a Luna:
O modelo deve ser instruído a emitir comandos neste formato exato:
<<<<<<< SEARCH Texto original exato que existe no artefato e que deve ser localizado pelo sistema.
Novo texto que deve substituir o bloco
acima, contendo as alterações desejadas.
REPLACE
Mecanismo de Aplicação (Backend):
1. O sistema recebe o bloco SEARCH.
2. Executa uma busca no conteúdo atual do artefato ativo.
3. Se a correspondência for exata (ou tolerante a espaços em branco, dependendo da configuração), realiza a substituição pelo bloco REPLACE.
4. Se o bloco SEARCH não for encontrado (alucinação), o sistema retorna um erro explícito ao agente: "Erro: Bloco de busca não encontrado. Certifique-se de copiar o texto original exatamente como ele aparece no arquivo."
5. O agente, recebendo o erro, tenta novamente corrigindo o bloco de busca. Esse loop de auto-correção é fundamental para a estabilidade.32
4.3 JSON Schema e Saída Estruturada
Para garantir que o modelo use essas ferramentas corretamente, devemos forçar Saídas Estruturadas (Structured Outputs) via JSON Schema. Frameworks modernos permitem definir a ferramenta de edição como um objeto Pydantic, garantindo que o modelo nunca esqueça campos obrigatórios como artifact_id.39
Exemplo de Schema para Ferramenta de Edição:


JSON




{
 "name": "apply_change",
 "description": "Applies a change to an artifact using search and replace blocks.",
 "parameters": {
   "type": "object",
   "properties": {
     "artifact_id": {"type": "string", "description": "UUID of the artifact to modify"},
     "changes": {
       "type": "array",
       "items": {
         "type": "object",
         "properties": {
           "search": {"type": "string", "description": "Exact text to find"},
           "replace": {"type": "string", "description": "New text to insert"}
         },
         "required": ["search", "replace"]
       }
     }
   },
   "required": ["artifact_id", "changes"]
 }
}

Usar esse esquema rigoroso impede o "bug" onde o modelo tenta explicar a edição em linguagem natural em vez de executar o comando.
________________
Parte 5: Orquestração e Referências Cruzadas
A exigência de suportar "referências cruzadas" (ex: artigo citando código) e a alternância de tipos exige um cérebro central: o Supervisor.
5.1 O Padrão Supervisor (Router Agent)
O Supervisor é o guardião do estado. Ele não escreve código nem texto. Ele lê a intenção do usuário e manipula o grafo.18
Fluxo de Controle:
1. Usuário: "Agora crie um artigo explicando esse código."
2. Supervisor (Input): Analisa a mensagem. Detecta intenção de "Novo Artefato" do tipo "Texto". Detecta referência ao "Artefato Ativo" (Código).
3. Supervisor (Ação):
   * Chama ferramenta create_artifact(type="markdown", title="Artigo Explicativo").
   * Atualiza o estado: active_artifact_id = novo_id.
   * Cria aresta de dependência: dependency_graph.add_edge(novo_id, id_codigo).
   * Transfere controle (Handoff) para o WriterAgent.
4. WriterAgent: Recebe o contexto. Vê que tem um artefato ativo vazio (o artigo) e um artefato de referência somente-leitura (o código). Começa a gerar o texto.
Essa separação de responsabilidades (Supervisor decide, Agentes executam) é a chave para a estabilidade. O Supervisor garante que o contexto do WriterAgent esteja limpo e focado apenas em escrita, evitando a contaminação com regras de codificação.19
5.2 Gerenciamento de Dependências e Referências Cruzadas
Para que as referências sejam robustas, a Luna deve manter um Grafo de Dependência oculto.
* Quando o Agente de Escrita cita o código (ex: "A função main na linha 10..."), o sistema deve idealmente criar um link semântico.
* Se o Agente de Código posteriormente altera a função main, o sistema consulta o grafo de dependência.
* Detecta que o Artigo depende do Código.
* Emite um alerta de "Stale Reference" (Referência Obsoleta): "Atenção: O código referenciado pelo Artigo mudou. O artigo pode estar desatualizado."
* O Supervisor pode então sugerir ao usuário: "O código mudou. Deseja que eu atualize a explicação no artigo?"
Isso transforma a Luna de um editor passivo em um assistente proativo que mantém a coerência entre múltiplos artefatos.7
5.3 Compilação de Contexto (Context Compilation)
Finalmente, para lidar com a limitação de tokens ao ter 10 ou 20 artefatos, usamos a técnica de Compilação de Contexto.
Antes de chamar o LLM, o sistema "monta" o prompt dinamicamente:
1. Artefato Ativo: Incluído integralmente (editável).
2. Dependências Diretas: Incluídas integralmente ou parcialmente (somente leitura).
3. Outros Artefatos: Incluídos apenas como uma lista de resumo (Título + Resumo de 1 linha).
Se o agente precisar ver um artefato que está apenas resumido, ele deve usar uma ferramenta read_artifact(id) para trazê-lo para o contexto. Isso é análogo ao gerenciamento de memória virtual em sistemas operacionais (paginação), garantindo que a Luna possa escalar para projetos complexos sem estourar a janela de contexto do LLM.9
________________
Conclusão Técnica
A implementação de suporte robusto a múltiplos artefatos na Luna não é uma mera atualização de feature, mas uma refatoração arquitetural fundamental. A transição de um estado linear para um Grafo de Estado Persistente, orquestrado por um Supervisor e manipulado via Ferramentas de Edição Estruturada (MCP), eliminará as instabilidades de criação e alternância de artefatos.
Ao adotar padrões industriais como LangGraph para o controle de fluxo e Aider/Canvas para a estratégia de edição, a Luna se posicionará não apenas como um chatbot, mas como uma IDE cognitiva capaz de realizar engenharia de software complexa e criação de conteúdo multi-modal com consistência e confiabilidade.
Referências citadas
1. What is the canvas feature in ChatGPT and how do I use it? - OpenAI Help Center, acessado em janeiro 1, 2026, https://help.openai.com/en/articles/9930697-what-is-the-canvas-feature-in-chatgpt-and-how-do-i-use-it
2. Introducing canvas, a new way to write and code with ChatGPT. | OpenAI, acessado em janeiro 1, 2026, https://openai.com/index/introducing-canvas/
3. LangGraph Uncovered: Building Stateful Multi-Agent Applications with LLMs-Part I, acessado em janeiro 1, 2026, https://dev.to/sreeni5018/langgraph-uncovered-building-stateful-multi-agent-applications-with-llms-part-i-p86
4. Multi-agent system - Wikipedia, acessado em janeiro 1, 2026, https://en.wikipedia.org/wiki/Multi-agent_system
5. Why Do Multi-Agent LLM Systems Fail? - arXiv, acessado em janeiro 1, 2026, https://arxiv.org/html/2503.13657v1
6. Why Do Multi-Agent LLM Systems Fail? - arXiv, acessado em janeiro 1, 2026, https://arxiv.org/pdf/2503.13657
7. Background Coding Agents: Context Engineering (Part 2), acessado em janeiro 1, 2026, https://engineering.atspotify.com/2025/11/context-engineering-background-coding-agents-part-2
8. LLMs Get Lost In Multi-Turn Conversation - arXiv, acessado em janeiro 1, 2026, https://arxiv.org/html/2505.06120v1
9. LLM Chat History Summarization Guide October 2025 - Mem0, acessado em janeiro 1, 2026, https://mem0.ai/blog/llm-chat-history-summarization-guide-2025
10. Building Agents That Remember: State Management in Multi-Agent AI Systems, acessado em janeiro 1, 2026, https://ranjankumar.in/building-agents-that-remember-state-management-in-multi-agent-ai-systems/
11. Why Multi-Agent LLM Systems Fail (and How to Fix Them) - Augment Code, acessado em janeiro 1, 2026, https://www.augmentcode.com/guides/why-multi-agent-llm-systems-fail-and-how-to-fix-them
12. Graph API overview - Docs by LangChain, acessado em janeiro 1, 2026, https://docs.langchain.com/oss/python/langgraph/graph-api
13. Part 1: How LangGraph Manages State for Multi-Agent Workflows (Best Practices) - Medium, acessado em janeiro 1, 2026, https://medium.com/@bharatraj1918/langgraph-state-management-part-1-how-langgraph-manages-state-for-multi-agent-workflows-da64d352c43b
14. LangGraph: Build Stateful AI Agents in Python, acessado em janeiro 1, 2026, https://realpython.com/langgraph-python/
15. Building Multi Agent Systems using LangGraph | by Sathwick - Medium, acessado em janeiro 1, 2026, https://medium.com/@sathwickreddy/building-multi-agent-systems-using-langgraph-2e6055066336
16. LangGraph overview - Docs by LangChain, acessado em janeiro 1, 2026, https://docs.langchain.com/oss/python/langgraph/overview
17. LangGraph Multi-Agent Systems: Complete Tutorial & Examples - Latenode, acessado em janeiro 1, 2026, https://latenode.com/blog/ai-frameworks-technical-infrastructure/langgraph-multi-agent-orchestration/langgraph-multi-agent-systems-complete-tutorial-examples
18. Building Multi-Agent Systems with LangGraph-Supervisor - DEV Community, acessado em janeiro 1, 2026, https://dev.to/sreeni5018/building-multi-agent-systems-with-langgraph-supervisor-138i
19. langgraph-supervisor - LangChain Docs, acessado em janeiro 1, 2026, https://reference.langchain.com/python/langgraph/supervisor/
20. Understanding the LangGraph Multi-Agent Supervisor | by akanshak - Medium, acessado em janeiro 1, 2026, https://medium.com/@akanshak/understanding-the-langgraph-multi-agent-supervisor-00fa1be4341b
21. LangGraph: Multi-Agent Workflows - LangChain Blog, acessado em janeiro 1, 2026, https://blog.langchain.com/langgraph-multi-agent-workflows/
22. Building AI Agents Using LangGraph: Part 6 — Using Multiple Schemas for Enhanced State Management | by HARSHA J S, acessado em janeiro 1, 2026, https://harshaselvi.medium.com/building-ai-agents-using-langgraph-part-6-using-multiple-schemas-for-enhanced-state-64d1ffdb71df
23. langchain-ai/langgraph-swarm-py: For your multi-agent needs - GitHub, acessado em janeiro 1, 2026, https://github.com/langchain-ai/langgraph-swarm-py
24. Model Context Protocol (MCP). MCP is an open protocol that… | by Aserdargun | Nov, 2025, acessado em janeiro 1, 2026, https://medium.com/@aserdargun/model-context-protocol-mcp-e453b47cf254
25. Resources - Model Context Protocol, acessado em janeiro 1, 2026, https://modelcontextprotocol.io/specification/2025-06-18/server/resources
26. Code execution with MCP: building more efficient AI agents \ Anthropic, acessado em janeiro 1, 2026, https://www.anthropic.com/engineering/code-execution-with-mcp
27. Architecture overview - Model Context Protocol, acessado em janeiro 1, 2026, https://modelcontextprotocol.io/docs/learn/architecture
28. Model Context Protocol—Deep Dive (Part 1/3) — Concept | by A B Vijay Kumar | Medium, acessado em janeiro 1, 2026, https://abvijaykumar.medium.com/model-context-protocol-deep-dive-part-1-3-concept-d9865898a2b0
29. JSON Whisperer: Efficient JSON Editing with LLMs - arXiv, acessado em janeiro 1, 2026, https://arxiv.org/html/2510.04717v1
30. Diff Format Explained: Search-Replace Blocks & AI Code Editing Limits | Morph, acessado em janeiro 1, 2026, https://morphllm.com/edit-formats/diff-format-explained
31. Edit formats - Aider, acessado em janeiro 1, 2026, https://aider.chat/docs/more/edit-formats.html
32. Code Surgery: How AI Assistants Make Precise Edits to Your Files - Fabian Hertwig's Blog, acessado em janeiro 1, 2026, https://fabianhertwig.com/blog/coding-assistants-file-edits/
33. aider/aider/coders/editblock_prompts.py at main - GitHub, acessado em janeiro 1, 2026, https://github.com/Aider-AI/aider/blob/main/aider/coders/editblock_prompts.py
34. aider/aider/coders/editblock_coder.py at main - GitHub, acessado em janeiro 1, 2026, https://github.com/paul-gauthier/aider/blob/main/aider/coders/editblock_coder.py
35. Architecting efficient context-aware multi-agent framework for production, acessado em janeiro 1, 2026, https://developers.googleblog.com/architecting-efficient-context-aware-multi-agent-framework-for-production/
36. Effective context engineering for AI agents - Anthropic, acessado em janeiro 1, 2026, https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents
37. An Analysis of the Claude 4 System Prompt - PromptHub, acessado em janeiro 1, 2026, https://www.prompthub.us/blog/an-analysis-of-the-claude-4-system-prompt
38. The Complete Guide to Managing Conversation History in Multi-Agent AI Systems - Medium, acessado em janeiro 1, 2026, https://medium.com/@_Ankit_Malviya/the-complete-guide-to-managing-conversation-history-in-multi-agent-ai-systems-0e0d3cca6423
39. Structured Output Generation in LLMs: JSON Schema and Grammar-Based Decoding | by Emre Karatas | Medium, acessado em janeiro 1, 2026, https://medium.com/@emrekaratas-ai/structured-output-generation-in-llms-json-schema-and-grammar-based-decoding-6a5c58b698a6
40. The guide to structured outputs and function calling with LLMs - Agenta, acessado em janeiro 1, 2026, https://agenta.ai/blog/the-guide-to-structured-outputs-and-function-calling-with-llms
41. How JSON Schema Works for LLM Data - Ghost, acessado em janeiro 1, 2026, https://latitude-blog.ghost.io/blog/how-json-schema-works-for-llm-data/